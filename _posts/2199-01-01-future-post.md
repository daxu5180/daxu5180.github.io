---
title: 'System Thinking in E-commerce ML'
date: 2022-12-01
permalink: 
tags:
  - Machine Learning
  - System Thinking
  - Industrial Production
---

In the past one year or so, I've been actively promoting the concept of system thinking for designing and developing recommender systems. I use this blog post to document my thought processes.  

The concept of system thinking first occurred to me back in 2019, a time when deep learning was leading and rejuvenating every succeeded or failed ideas in our industry. While I was also using deep learning in production and publishing deep learning papers, I sensed something that conceptually felt wrong – deep learning is merely an algorithmic approach to learn patterns from past data, and why should we expect it to magically empower a system that operates on tons of other components? If not worse, how much do we know about the algorithmic nature of deep learning, what does it guarantee, when does it fail and why?

For disclaimer, I am not against the use of deep learning – I think only a truly ignorant person will staty away from deep learning in the year 2022. However, I believe there are two clouds on deep learning, and I am afraid there is no free silver lining behind them. Let's start by recalling how we were trained to do statistical analysis (or in modern phrase, machine learning) in college, which predicts an interesting outcome using linear regression. Theoretically, we can justify almost everything, from what the model is capable of expressing, can we effectively find the global optimum of the empirical risk minimization, how does that particular solution behave on unseen samples, and a bunch of other asymptotic and non-asymptotic properties. Engineering-wise, we have enough guidance to implement, debug, and iterate the model to ensure it achieves the best expected outcome. How much of these facts can be said for deep learning?

More is unknown than that have been revealed for deep learning’s mechanisms, and each step forward has heavier costs. Personally, I have also made small contributions to understanding deep learning models, and from the statistical viewpoint which I’m particularly interested in, we can indeed prove many properties about deep learning models. But what we have cracked so far are mostly limited to simpler scenarios, such as using two-layer MLP with SGD on i.i.d data. In general, deep learning models are too complex to study factor-by-factor: there are combinatorically many configurations that may exhibit different behaviors. So while academic investigations have revealed the role of many individual components, how to best assemble them and make sure they work together is nothing like playing with Lego. Deep learning in remains a lab science, much like how biomedical lab workers decipher protein structures by experimenting combinatorically many configurations one-by-one.

What this means is that making deep learning work requires intensive human labor, sometimes so intense that it becomes an unwise investment. Two decades ago, an engineering team in the automotive industry may only need a couple of data scientists to develop and maintain linear regression models. Critics may argue that modern problems are far more complex these days, which I completely agree, but those linear models are still helping Ford and GM make billions of dollars a year. Also remember that linear models helped NASA sent people to the moon – even the rocket science have found basic models good enough. In contrast, let’s think about how many data and ML engineer teams we need today to develop and maintain a deep learning model that can slightly improve GMV? I think what matters here is the benefit-cost ratio: eventually people will realize how quickly deep learning reaches the boundary of its benefit-cost ratio, and I personally guess Elon Musk started firing Twitter's entire ML teams because he suspects the same thing. If Twitter doesn't need more complex ML solutions to sustain its business, why should other tech companies?

Newcomer to this field may despise my arguments, as thousands of accomplishments are published in top-notch ML conferences every year – some of which must be truly groundbreaking. I apologize for sacrificing specialty at the expense of generality, but the academic way of developing machine learning solutions has been proved inadequate for solving industry problems, especially for recommendation. I could publish ten relevant papers and still not solve a problem in the company. The main gap lies in openness of the target environment, and this gap has gradually driven academic and industrial solutions apart, conceptually and empirically. Darwin's theory of evolution, though somewhat inappropriate in our context, is a good analogy that explains how academic and industrial workers end up as two species by surviving their unique environments. The gap is quite self-explanatory if you have some experience with both worlds: academia approaches are often developed under restrictive environments with the aim of rigorously formulating, justifying, and evaluating the approach; while industrial approach must account for the unpredictable and uncontrollable factors in an open environment. In other words, academia workers can situate themselves in a well-defined world while industrial workers have to deal with the chaotic and unknown nature of the real world. How does it affect people’s opinion for problem-solving?

By Occam’s Razor, simpler solutions are more likely to adapt to the increasingly complex and frequently changing business tasks and real-world environments. It is no surprise that many  of the industry’s mature and time-tested solutions are not that complex. On the other hand, the academia is more critical about constantly altering the well-defined environments, as the same set of problems have been studied for decades. I am not criticizing academic problems since they have also been evolved and tested by the academia community. But living in a well-defined world can cause people’s mentality to become solution-driven rather than problem-driven. In other words, because there lack open-ended components in the problem, the benefits of a proposed solution can be easily stated – it encourages academic workers to emphasize how the advancement of a solution fits the well-defined problem, even to an extend where it is unclear how the problem fits in real world. The chaotic, unpredictable, and uncontrollable factors in the environment are less considered because they belong to the problem definition, not the problem-solution compatibility that can be rigorously examined (and thus favored) by the academia. Therefore, in the long run, academia solutions will have a lot of subtlety, novelty, and complexity; while the problems for which they are best suited can be considered too restrictive by the industry.

Given the above context, I will explain why system thinking is bridge that might eliminate the discrepancies in science and practice. In particular, system thinking emphasizes the interconnections of things, which will force people to recognize the vague and complex definitions of an otherwise straightforward problem. You may find this familiar because the product managers often revise the definitions of a problem which we could have solved comfortably. In many cases, product managers follow a strict problem-driven approach which prioritize exploring the problem itself by accounting for all potential factors involved. While what they are doing are often wrong (because they can fail to perceive that only a certain subset of factors can be addressed by the limited data and model capability, i.e. we should focus on solving the problem rather than exploring it endlessly), the thinking process of treating things in an open world have proved valuable for balancing problem-driven and solution-driven approaches. 

The key to system thinking is to understand how everything is connected to everything else. With a holistic view of an open-ended problem, we are more likely to learn and identify the key leverage points (such as particular patterns in the data or advantage of a model) faster, avoid the resistance from the unpredictable and uncontrollable environment, and most importantly, making our decision consistent with the target goal. In fact, system thinking has been widely adopted by other disciplines including physics, biology, and control theory. Like those disciplines, machine learning has developed plenty technical tools and mathematical models. However, the real challenges of developing recommender system in e-commerce are not purely technical, for instance, the performance of recommender systems will be affected by many human, market and economic factors that has no pure technical solutions in the real world. Failure to account for open environment will lead to unanticipated side effects. 

In my experience, unanticipated side effects, especially the resistance from environment that blocks the recommender system achieving desired effect, first arises from the mismatch between the dynamic complexity of the system we build and our cognitive ability to understand that complexity. This is not only because we might use the wrong technical knowledge and tools to model the problem, but our prior belief can systematically lead us to incorrect assumptions about the system-environment interactions, even in the simplest cases. In particular, our prior belief often fails to account for the constantly changing environment, how pipelines and acting components are tightly coupled in a production system, the fact that our decisions and the future environment are governed by feedback loops, the way that customers self-organize and adapt to our systems, the delays in feedback channels, and the resisting factors that make seemingly obvious solutions fail. 

While an open-end environment is dynamic, evolving, and interconnected, our prior beliefs are often static, shallow, and isolated. A root cause of this phenomenon is that our heuristics about the causal attributions of the system often fails to cover the open-world complexity (i.e. the limitations of human minds), and unfortunately our erroneous beliefs are reinforced by our selective judgement of the facts. Therefore, the first step of system thinking is to abandon the static and isolated views of recommendation problems, and try to think about the dynamics, evolvement, and interconnections. Our understanding of the dynamics and evolvement, in particular, should build on the fact that our decision will interfere with the feedback we observe in the future. 

Then there comes the second cause of unanticipated side effects: we do not understand the full-range feedback operating in an open-end environment. We do not observe how users behave elsewhere, how rivalry websites affects their decision-makings, what local events are happening, and many others. While we can gather as much information as we can, partial information can be as harmful as no information at all – using partial information can lead to attribution errors and false causal conclusions.  For complex systems, cause and effect can be distant in time and space. The attribution of feedback behaviors to users and their characteristics can divert our attention from the high leverage point, which is to improve the system by exploiting the structure of the problem. A fully personalized system is no personalization at all: the ultimate form of personalization is not to understand John, Alice, User 000108, but to understand what makes an average human to behave in such ways. Another factor is the delays in feedback, which affects our ability to test hypothesis and learn the real patterns. The oscillation and instability of open-end environment can be easily observed if we keep the treatment and control system running and look at the conclusions drawn from different time segments. Therefore, calibration and sensitivity analysis are helpful in many cases.

I would like to mention that this monologue is not indented to be a problem-solving tutorial. Nor am I proposing any engineering solution because I believe no models can replace thinking. Whatever we choose to build recommender systems should facilitate the process of system thinking, even if many of the above problems cannot be readily solved. As engineers and data scientists, our data-inquiry skills should be used to correct our biases and judgmental errors rather than reinforcing them; and we should always be aware of confirmation errors, hindsight, defensive thinking, herd mentality, and that all models are wrong but some are useful. For academic research, system thinking is an useful tool for bringing models out of the lab. As you can tell, system thinking reveals all the harsh truth about open-ended environments, and any research direction that address those issues will be practical and problem-driven by nature. 
Finally, one of my most valuable lessons learnt is that working with critics is the best way to improve our understanding of an open-ended environment. This process can lead to the changes in our prior belief and conception of the unpredictable and uncontrollable factors. I guess there is no need for me to elaborate this point as we all have such experiences. To end this monologue, I would like to emphasize a few high-level guidance from system thinking:
<ol>
<li>The purpose of developing a system is always to solve a problem, not only to gain insight, though the insight will be useful for exploration and research. Solutions with simple models or even rules shall be appreciated if they solve the problem. Complex models often give us insights, but using them to solve problems can have a poor ROI.</li>
<li>Our model and data analysis should have broad boundaries to deal with all the issues of not having full-range feedback, erroneous causal attributions, the delay, and other unaccounted factors such as users’ decision making. If you feel that a hypothesis or scenario is restrictive, it is. </li>
<li>Critics, product people, users, and all parties to our service should be engaged as partners from the beginning. Their opinion will help us accumulating better mental models.</li>
<li>Building recommender system is an iterative and continual process of testing and redesign, both for the ML model and our prior belief. Everything in the environment is dynamic, evolving, and interconnected, and so should our strategies and mindset.</li>
</ol>